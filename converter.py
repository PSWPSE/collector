import os
from datetime import datetime
from pathlib import Path
import anthropic
from dotenv import load_dotenv
import re

class NewsConverter:
    def __init__(self):
        load_dotenv()
        self.client = anthropic.Anthropic(
            api_key=os.getenv('ANTHROPIC_API_KEY')
        )
        self.output_dir = Path('converted_articles')
        self.output_dir.mkdir(exist_ok=True)

    def read_txt_file(self, file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # Parse the content
        title_match = re.search(r'ì œëª©: (.*?)\n={2,}', content)
        meta_match = re.search(r'ë©”íƒ€ ì •ë³´:\ndescription: (.*?)\n-{2,}', content, re.DOTALL)
        content_match = re.search(r'ë³¸ë¬¸:\n(.*?)$', content, re.DOTALL)
        
        title = title_match.group(1) if title_match else ""
        description = meta_match.group(1).strip() if meta_match else ""
        main_content = content_match.group(1).strip() if content_match else ""
        
        return {
            'title': title,
            'description': description,
            'content': main_content
        }

    def clean_response(self, response):
        """Clean the API response text"""
        # Convert to string and remove TextBlock formatting
        text = str(response)
        text = re.sub(r'\[.*?\]', '', text)
        text = text.replace('TextBlock(citations=None, text=', '')
        text = text.replace(', type=\'text\')', '')
        
        # Remove extra quotes and newlines at the start
        text = text.strip('"\'')
        text = text.lstrip('\n')
        
        # Replace escaped newlines with actual newlines
        text = text.replace('\\n', '\n')
        
        return text.strip()

    def extract_keywords(self, content):
        """Extract keywords from content using Claude"""
        prompt = f"""ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ê¸°ì‚¬ì—ì„œ 5-7ê°œì˜ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ í•´ì‹œíƒœê·¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
        
        ê·œì¹™:
        1. í•´ì‹œíƒœê·¸ëŠ” í•œê¸€ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„± (#í‚¤ì›Œë“œ)
        2. ê° í•´ì‹œíƒœê·¸ëŠ” ê³µë°±ìœ¼ë¡œ êµ¬ë¶„
        3. ì£¼ì‹ ì¢…ëª©ì´ ì–¸ê¸‰ëœ ê²½ìš° ë°˜ë“œì‹œ í¬í•¨
        4. ê°€ì¥ ì¤‘ìš”í•œ ì£¼ì œì–´ ìœ„ì£¼ë¡œ ì„ ì •
        5. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ë‚˜ ì„¤ëª… ì—†ì´ í•´ì‹œíƒœê·¸ë§Œ ë°˜í™˜
        
        ì˜ˆì‹œ í˜•ì‹:
        #í‚¤ì›Œë“œ1 #í‚¤ì›Œë“œ2 #í‚¤ì›Œë“œ3 #í‚¤ì›Œë“œ4 #í‚¤ì›Œë“œ5
        
        Article: {content}"""
        
        message = self.client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=300,
            temperature=0,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
        return self.clean_response(message.content[0])

    def generate_markdown_content(self, content):
        """Generate markdown content using Claude"""
        example = """ğŸ’° í¬ë¼ì¼„, ì•”í˜¸í™”í ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€ ìœ„í•´ í˜ì‹ ì ì¸ P2P ê²°ì œì•± ì¶œì‹œ

â–¶ í‘œê²° í˜„í™©:
â€¢ "vote-a-rama" ìƒˆë²½ê¹Œì§€ ì§€ì†, ì¢…ë£Œ ì‹œì  ë¶ˆíˆ¬ëª…
â€¢ ì¼ì¶œ ì „ ìµœì¢… í‘œê²° ê°€ëŠ¥ì„± ìˆë‹¤ê³  ì–¸ë¡  ë³´ë„
â€¢ í™”ìš”ì¼ë¶€í„° ê³„ì†ëœ ìˆ˜ì •ì•ˆ í‘œê²° ê³¼ì •

â–¶ í†µê³¼ ì¡°ê±´:
â€¢ ìƒì› 100ëª… ì¤‘ í†µìƒ 60ëª… ì°¬ì„± í•„ìš”í•˜ì§€ë§Œ "reconciliation" ì ˆì°¨ë¡œ ê³¼ë°˜ìˆ˜ë§Œ í•„ìš”
â€¢ ê³µí™”ë‹¹ ê·¼ì†Œí•œ ìƒì› ì¥ì•…, ë¯¼ì£¼ë‹¹ ê°•ë ¥ ë°˜ëŒ€

â–¶ ë²•ì•ˆ ë‚´ìš©ê³¼ ë¹„ìš©:
1. 2017ë…„ íŠ¸ëŸ¼í”„ ì„¸ê¸ˆê°ë©´ ì—°ì¥
2. ì‹ ê·œ ì„¸ê¸ˆê°ë©´ ë„ì…
3. êµ­ë°©Â·êµ­ê²½ë³´ì•ˆ ì§€ì¶œ ì¦ê°€

â–¶ ë‚´ë¶€ ê°ˆë“±:
â€¢ ì¼ë¡  ë¨¸ìŠ¤í¬ "ë¯¸ì¹œ ë²•ì•ˆ"ì´ë¼ ê°•ë ¥ ë¹„íŒ, ì‹ ì •ë‹¹ ì°½ë‹¹ ìœ„í˜‘
â€¢ í…ŒìŠ¬ë¼ $TSLA ë³´ì¡°ê¸ˆ ì² íšŒ ìœ„í˜‘ìœ¼ë¡œ ì‘ìˆ˜"""

        prompt = f"""ë‹¹ì‹ ì€ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í•œêµ­ì–´ ìŠ¤íƒ€ì¼ì˜ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ì˜ í˜•ì‹ê³¼ ìŠ¤íƒ€ì¼ì„ ì •í™•íˆ ë”°ë¼ ë³€í™˜í•´ì£¼ì„¸ìš”.

        í•„ìˆ˜ í˜•ì‹:
        1. ì œëª© í˜•ì‹: ì´ëª¨ì§€ ì œëª©ë‚´ìš©
           ì˜ˆì‹œ: "ğŸ’° í¬ë¼ì¼„, ì•”í˜¸í™”í ì‹œì¥ ì ìœ ìœ¨ í™•ëŒ€ ìœ„í•´ í˜ì‹ ì ì¸ P2P ê²°ì œì•± ì¶œì‹œ"
           - ì œëª© ì‹œì‘ì— ë‚´ìš©ì„ ì˜ í‘œí˜„í•˜ëŠ” ì´ëª¨ì§€ í•˜ë‚˜ë§Œ ì‚¬ìš©
           - ì œëª©ì€ ë°˜ë“œì‹œ ì²« ì¤„ì— ìœ„ì¹˜
           - ì œëª© ë‹¤ìŒì—ëŠ” ë¹ˆ ì¤„ í•˜ë‚˜ ì¶”ê°€
           - ì œëª©ì€ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆê²Œ ì‘ì„±
           - ë‹¨ìˆœ ì‚¬ì‹¤ ë‚˜ì—´ë³´ë‹¤ëŠ” í•µì‹¬ ê°€ì¹˜ë‚˜ ì˜ë¯¸ë¥¼ ë‹´ì•„ ì‘ì„±

        2. ì„¹ì…˜ êµ¬ì¡°:
           - ê° ì£¼ìš” ì„¹ì…˜ì€ â–¶ë¡œ ì‹œì‘
           - ì„¹ì…˜ ì œëª©ì€ ëª…ì‚¬í˜•ìœ¼ë¡œ ëë‚¨ (ì˜ˆ: "í˜„í™©:", "ì „ë§:", "ì˜í–¥:")
           - ì„¹ì…˜ ì œëª© ë’¤ì—ëŠ” ë°˜ë“œì‹œ ì½œë¡ (:) ì‚¬ìš©

        3. ê¸€ë¨¸ë¦¬ ê¸°í˜¸:
           - ì£¼ìš” ì‚¬ì‹¤/í˜„í™©ì€ â€¢ ê¸°í˜¸ ì‚¬ìš©
           - ìˆœì°¨ì  ë‚´ìš©ì´ë‚˜ ìƒì„¸ ì„¤ëª…ì€ 1. 2. 3. ë²ˆí˜¸ ì‚¬ìš©
           - ì¸ìš©êµ¬ë‚˜ ë°œì–¸ì€ ë”°ì˜´í‘œ(" ") ì‚¬ìš©

        4. ë¬¸ì²´ì™€ í†¤:
           - ê°ê´€ì ì´ê³  ëª…í™•í•œ ë¬¸ì²´ ì‚¬ìš©
           - ë¬¸ì¥ì€ ê°„ê²°í•˜ê²Œ, ë˜ë„ë¡ 1-2ì¤„ ì´ë‚´ë¡œ ì‘ì„±
           - ì „ë¬¸ ìš©ì–´ëŠ” ê°€ëŠ¥í•œ í•œê¸€ë¡œ í’€ì–´ì„œ ì„¤ëª…
           - ìˆ«ìë‚˜ í†µê³„ëŠ” ë‹¨ìœ„ì™€ í•¨ê»˜ ëª…í™•íˆ í‘œê¸°

        5. êµ¬ì¡°í™”:
           - ì¤‘ìš”ë„ì™€ ì‹œê°„ ìˆœì„œë¥¼ ê³ ë ¤í•œ ì„¹ì…˜ ë°°ì¹˜
           - ê´€ë ¨ ë‚´ìš©ì€ ê°™ì€ ì„¹ì…˜ì— ëª¨ì•„ì„œ ì •ë¦¬
           - ì„¹ì…˜ ê°„ ì ì ˆí•œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ê°€ë…ì„± í™•ë³´
           - ë§ˆì§€ë§‰ì—ëŠ” í–¥í›„ ì „ë§ì´ë‚˜ ê²°ë¡  í¬í•¨

        6. íŠ¹ë³„ ê·œì¹™:
           - ì£¼ì‹ ì¢…ëª©ëª…ì´ ë‚˜ì˜¤ë©´ ë°˜ë“œì‹œ ì¢…ëª©ëª… ë’¤ì— $ì‹¬ë³¼ í‘œê¸°
           ì˜ˆ: í…ŒìŠ¬ë¼ $TSLA, ì• í”Œ $AAPL
           - ê´„í˜¸ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê³µë°±ìœ¼ë¡œ êµ¬ë¶„

        ì˜ˆì‹œ í˜•ì‹:
        {example}

        ì…ë ¥ ë°ì´í„°:
        ì œëª©: {content['title']}
        ì„¤ëª…: {content['description']}
        ë³¸ë¬¸: {content['content']}

        ì œëª©ì€ ë°˜ë“œì‹œ ì²« ì¤„ì— ìœ„ì¹˜í•˜ê³ , ë‚´ìš©ì„ ì˜ í‘œí˜„í•˜ëŠ” ì´ëª¨ì§€ í•˜ë‚˜ë¥¼ ì‹œì‘ì— ë„£ì–´ì£¼ì„¸ìš”.
        ì œëª©ì€ ë‹¨ìˆœíˆ ì‚¬ì‹¤ì„ ë‚˜ì—´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë‚´ìš©ì˜ í•µì‹¬ ê°€ì¹˜ë‚˜ ì˜ë¯¸ë¥¼ ë‹´ì•„ ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ì´ëª¨ì§€ ì„ íƒ ê°€ì´ë“œ:
        - ê¸ˆìœµ/íˆ¬ì ê´€ë ¨: ğŸ’° ğŸ’µ ğŸ“ˆ ğŸ“Š
        - ê¸°ìˆ /í˜ì‹  ê´€ë ¨: ğŸš€ ğŸ’¡ ğŸ”§ ğŸŒŸ
        - ì •ì±…/ê·œì œ ê´€ë ¨: âš–ï¸ ğŸ“œ ğŸ›ï¸ ğŸ”¨
        - ê°ˆë“±/ê²½ìŸ ê´€ë ¨: ğŸ”¥ âš”ï¸ ğŸ¯ ğŸ²
        - í˜‘ë ¥/ê³„ì•½ ê´€ë ¨: ğŸ¤ ğŸ“ ğŸŠ ğŸŒˆ
        - ì„±ì¥/ë°œì „ ê´€ë ¨: ğŸŒ± ğŸ‰ ğŸ’ª â­
        """
        
        message = self.client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=2000,
            temperature=0,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
        response = self.clean_response(message.content[0])
        
        # Ensure the title is properly formatted
        if not response.startswith(('ğŸ’°', 'ğŸ’µ', 'ğŸ“ˆ', 'ğŸ“Š', 'ğŸš€', 'ğŸ’¡', 'ğŸ”§', 'ğŸŒŸ', 'âš–ï¸', 'ğŸ“œ', 'ğŸ›ï¸', 'ğŸ”¨', 'ğŸ”¥', 'âš”ï¸', 'ğŸ¯', 'ğŸ²', 'ğŸ¤', 'ğŸ“', 'ğŸŠ', 'ğŸŒˆ', 'ğŸŒ±', 'ğŸ‰', 'ğŸ’ª', 'â­')):
            # Get the first line as title
            lines = response.split('\n')
            title = lines[0].strip('() ')
            
            # Get title from input if first line is not suitable
            if len(title) < 10 or title.isdigit():
                title = content['title']
            
            # Format the title properly with a default emoji
            formatted_title = f"ğŸ“° {title}\n"
            
            # Replace the first line with formatted title
            response = formatted_title + '\n'.join(lines[1:])
        
        # Fix stock symbol format
        response = re.sub(r'(\w+)\((\$[A-Z]+)\)', r'\1 \2', response)
        
        return response

    def convert_to_markdown(self, data):
        """Convert parsed data to markdown format"""
        # Generate markdown content
        markdown_content = self.generate_markdown_content(data)
        
        # Extract keywords
        keywords = self.extract_keywords(f"{data['title']}\n{data['description']}\n{data['content']}")
        
        # Combine content and keywords with proper spacing
        final_content = f"{markdown_content}\n\n{keywords}"
        
        return final_content

    def process_file(self, file_path):
        """Process a single TXT file"""
        print(f"Processing {file_path}...")
        data = self.read_txt_file(file_path)
        markdown_content = self.convert_to_markdown(data)
        
        # Create output filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"{Path(file_path).stem}_{timestamp}.md"
        output_path = self.output_dir / output_filename
        
        # Save markdown content
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"Created {output_path}")

    def process_directory(self, directory_path):
        """Process all TXT files in a directory"""
        directory = Path(directory_path)
        for txt_file in directory.glob('*.txt'):
            self.process_file(txt_file)

def main():
    import sys
    
    if len(sys.argv) != 2:
        print("Usage: python converter.py <txt_file_or_directory>")
        sys.exit(1)
    
    path = sys.argv[1]
    converter = NewsConverter()
    
    if os.path.isfile(path):
        converter.process_file(path)
    elif os.path.isdir(path):
        converter.process_directory(path)
    else:
        print(f"Error: {path} is not a valid file or directory")
        sys.exit(1)

if __name__ == '__main__':
    main() 