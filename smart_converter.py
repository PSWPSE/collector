import os
import re
from datetime import datetime
from pathlib import Path
from collections import Counter
from typing import Dict, List

class SmartNewsConverter:
    def __init__(self):
        """ì‹¤ìš©ì ì¸ ìŠ¤ë§ˆíŠ¸ ë‰´ìŠ¤ ë³€í™˜ê¸°"""
        self.output_dir = Path('converted_articles')
        self.output_dir.mkdir(exist_ok=True)
        
        # í¬ê´„ì ì¸ ê¸ˆìœµ/ê²½ì œ ë²ˆì—­ ì‚¬ì „
        self.translation_dict = {
            # ì‹œì¥ ê¸°ë³¸ ìš©ì–´
            'Asian stocks': 'ì•„ì‹œì•„ ì£¼ì‹',
            'stock market': 'ì£¼ì‹ ì‹œì¥',
            'equity market': 'ì£¼ì‹ ì‹œì¥',
            'financial market': 'ê¸ˆìœµ ì‹œì¥',
            'capital market': 'ìë³¸ ì‹œì¥',
            'bond market': 'ì±„ê¶Œ ì‹œì¥',
            'commodity market': 'ì›ìì¬ ì‹œì¥',
            'forex market': 'ì™¸í™˜ ì‹œì¥',
            'market volatility': 'ì‹œì¥ ë³€ë™ì„±',
            'market sentiment': 'ì‹œì¥ ì‹¬ë¦¬',
            'market outlook': 'ì‹œì¥ ì „ë§',
            'trading volume': 'ê±°ë˜ëŸ‰',
            'market cap': 'ì‹œê°€ì´ì•¡',
            'market share': 'ì‹œì¥ ì ìœ ìœ¨',
            
            # ì£¼ìš” ì§€ìˆ˜
            'Nikkei': 'ë‹ˆì¼€ì´',
            'Hang Seng': 'í•­ì…',
            'KOSPI': 'ì½”ìŠ¤í”¼',
            'Dow Jones': 'ë‹¤ìš°ì¡´ìŠ¤',
            'NASDAQ': 'ë‚˜ìŠ¤ë‹¥',
            'S&P 500': 'S&P 500',
            'FTSE': 'FTSE',
            'DAX': 'DAX',
            
            # í†µí™”
            'U.S. dollar': 'ë¯¸êµ­ ë‹¬ëŸ¬',
            'dollar': 'ë‹¬ëŸ¬',
            'Japanese yen': 'ì¼ë³¸ ì—”',
            'yen': 'ì—”',
            'euro': 'ìœ ë¡œ',
            'British pound': 'ì˜êµ­ íŒŒìš´ë“œ',
            'pound': 'íŒŒìš´ë“œ',
            'Chinese yuan': 'ì¤‘êµ­ ìœ„ì•ˆ',
            'yuan': 'ìœ„ì•ˆ',
            'Korean won': 'í•œêµ­ ì›',
            'won': 'ì›',
            
            # ê²½ì œ ì§€í‘œ
            'GDP': 'GDP',
            'inflation': 'ì¸í”Œë ˆì´ì…˜',
            'interest rate': 'ê¸ˆë¦¬',
            'unemployment rate': 'ì‹¤ì—…ë¥ ',
            'employment': 'ê³ ìš©',
            'jobs report': 'ê³ ìš© ë³´ê³ ì„œ',
            'economic growth': 'ê²½ì œ ì„±ì¥',
            'recession': 'ê²½ê¸° ì¹¨ì²´',
            'recovery': 'ê²½ê¸° íšŒë³µ',
            'expansion': 'ê²½ê¸° í™•ì¥',
            
            # ì •ì±…/ê¸°ê´€
            'Federal Reserve': 'ì—°ë°©ì¤€ë¹„ì œë„',
            'Fed': 'ì—°ì¤€',
            'central bank': 'ì¤‘ì•™ì€í–‰',
            'monetary policy': 'í†µí™”ì •ì±…',
            'fiscal policy': 'ì¬ì •ì •ì±…',
            'government': 'ì •ë¶€',
            'administration': 'í–‰ì •ë¶€',
            'Congress': 'ì˜íšŒ',
            'Senate': 'ìƒì›',
            'House': 'í•˜ì›',
            
            # ê¸°ì—…/ë¹„ì¦ˆë‹ˆìŠ¤
            'earnings': 'ì‹¤ì ',
            'revenue': 'ë§¤ì¶œ',
            'profit': 'ì´ìµ',
            'loss': 'ì†ì‹¤',
            'IPO': 'IPO',
            'merger': 'í•©ë³‘',
            'acquisition': 'ì¸ìˆ˜',
            'dividend': 'ë°°ë‹¹ê¸ˆ',
            'stock split': 'ì£¼ì‹ ë¶„í• ',
            'buyback': 'ìì‚¬ì£¼ ë§¤ì…',
            
            # ë°©í–¥ì„±/ë³€í™”
            'rose': 'ìƒìŠ¹í–ˆë‹¤',
            'fell': 'í•˜ë½í–ˆë‹¤',
            'gained': 'ìƒìŠ¹í–ˆë‹¤',
            'declined': 'í•˜ë½í–ˆë‹¤',
            'increased': 'ì¦ê°€í–ˆë‹¤',
            'decreased': 'ê°ì†Œí–ˆë‹¤',
            'surged': 'ê¸‰ë“±í–ˆë‹¤',
            'plunged': 'ê¸‰ë½í–ˆë‹¤',
            'climbed': 'ì˜¬ëë‹¤',
            'dropped': 'ë–¨ì–´ì¡Œë‹¤',
            'jumped': 'ê¸‰ë“±í–ˆë‹¤',
            'slumped': 'ê¸‰ë½í–ˆë‹¤',
            'edged up': 'ì†Œí­ ìƒìŠ¹í–ˆë‹¤',
            'edged down': 'ì†Œí­ í•˜ë½í–ˆë‹¤',
            'rallied': 'ë°˜ë“±í–ˆë‹¤',
            'tumbled': 'ê¸‰ë½í–ˆë‹¤',
            
            # ì •ë„ í‘œí˜„
            'significantly': 'í¬ê²Œ',
            'substantially': 'ìƒë‹¹íˆ',
            'moderately': 'ì ë‹¹íˆ',
            'slightly': 'ì•½ê°„',
            'marginally': 'ë¯¸ë¯¸í•˜ê²Œ',
            'sharply': 'ê¸‰ê²©íˆ',
            'dramatically': 'ê·¹ì ìœ¼ë¡œ',
            
            # ì‹œê°„ í‘œí˜„
            'overnight': 'ì „ë‚  ë°¤',
            'premarket': 'ì¥ì „',
            'after hours': 'ì¥í›„',
            'trading session': 'ê±°ë˜ ì„¸ì…˜',
            'trading day': 'ê±°ë˜ì¼',
            'business day': 'ì˜ì—…ì¼',
            'weekend': 'ì£¼ë§',
            'weekday': 'í‰ì¼',
            
            # ê¸°íƒ€ ì¤‘ìš” ìš©ì–´
            'investors': 'íˆ¬ììë“¤',
            'traders': 'ê±°ë˜ìë“¤',
            'analysts': 'ë¶„ì„ê°€ë“¤',
            'experts': 'ì „ë¬¸ê°€ë“¤',
            'economists': 'ê²½ì œí•™ìë“¤',
            'strategists': 'ì „ëµê°€ë“¤',
            'portfolio': 'í¬íŠ¸í´ë¦¬ì˜¤',
            'hedge fund': 'í—¤ì§€í€ë“œ',
            'mutual fund': 'ë®¤ì¶”ì–¼í€ë“œ',
            'pension fund': 'ì—°ê¸°ê¸ˆ',
            'institutional investor': 'ê¸°ê´€íˆ¬ìì',
            'retail investor': 'ê°œì¸íˆ¬ìì'
        }
        
        # ì´ëª¨ì§€ ë§¤í•‘
        self.emoji_mapping = {
            'market': 'ğŸ“ˆ',
            'finance': 'ğŸ’°',
            'tech': 'ğŸš€',
            'policy': 'âš–ï¸',
            'trade': 'ğŸ¤',
            'energy': 'â›½',
            'default': 'ğŸ“°'
        }

    def smart_translate(self, text: str) -> str:
        """ìŠ¤ë§ˆíŠ¸ ë²ˆì—­ (ë¬¸ë§¥ ê³ ë ¤)"""
        # ìˆ«ìì™€ íŠ¹ìˆ˜ ê¸°í˜¸ ë³´ì¡´
        text = re.sub(r'(\d+\.?\d*%)', r'PERCENT_\1', text)
        text = re.sub(r'(\$\d+\.?\d*)', r'DOLLAR_\1', text)
        text = re.sub(r'(\d+\.?\d*)', r'NUMBER_\1', text)
        
        # ê³ ìœ ëª…ì‚¬ ë³´ì¡´ (ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ë‹¨ì–´)
        proper_nouns = re.findall(r'\b[A-Z][a-zA-Z]+\b', text)
        for i, noun in enumerate(proper_nouns):
            text = text.replace(noun, f'PROPER_{i}')
        
        # ë²ˆì—­ ì ìš©
        translated = text
        for en_term, ko_term in self.translation_dict.items():
            translated = re.sub(
                r'\b' + re.escape(en_term) + r'\b',
                ko_term,
                translated,
                flags=re.IGNORECASE
            )
        
        # ë³µì›
        for i, noun in enumerate(proper_nouns):
            translated = translated.replace(f'PROPER_{i}', noun)
        
        translated = re.sub(r'NUMBER_(\d+\.?\d*)', r'\1', translated)
        translated = re.sub(r'DOLLAR_(\$\d+\.?\d*)', r'\1', translated)
        translated = re.sub(r'PERCENT_(\d+\.?\d*%)', r'\1', translated)
        
        return translated

    def clean_and_structure(self, content: str) -> Dict[str, List[str]]:
        """ë‚´ìš© ì •ë¦¬ ë° êµ¬ì¡°í™”"""
        # ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°
        lines = content.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            # ê¸°ì ì •ë³´, ë©”íƒ€ë°ì´í„°, ì¤‘ë³µ ì œê±°
            if (line and len(line) > 20 and 
                not any(skip in line.lower() for skip in [
                    'kevin buckland', 'by ', 'reporting by', 'editing by',
                    'usd=x', '^spx', 'fri,', 'min read', 'terms and privacy',
                    'privacy dashboard', 'in this article'
                ])):
                cleaned_lines.append(line)
        
        # ì¤‘ë³µ ì œê±°
        unique_lines = list(dict.fromkeys(cleaned_lines))
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        categories = {
            'market_status': [],
            'economic_data': [],
            'policy_trade': [],
            'outlook': []
        }
        
        for line in unique_lines:
            line_lower = line.lower()
            
            if any(keyword in line_lower for keyword in [
                'market', 'stock', 'index', 'trading', 'nikkei', 'kospi', 'hang seng'
            ]):
                categories['market_status'].append(line)
            elif any(keyword in line_lower for keyword in [
                'jobs', 'employment', 'economic', 'data', 'gdp', 'inflation'
            ]):
                categories['economic_data'].append(line)
            elif any(keyword in line_lower for keyword in [
                'trump', 'president', 'trade', 'tariff', 'deal', 'policy'
            ]):
                categories['policy_trade'].append(line)
            elif any(keyword in line_lower for keyword in [
                'expect', 'forecast', 'outlook', 'ahead', 'future'
            ]):
                categories['outlook'].append(line)
            else:
                # ê°€ì¥ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ì— ì¶”ê°€
                if len(categories['market_status']) <= len(categories['policy_trade']):
                    categories['market_status'].append(line)
                else:
                    categories['policy_trade'].append(line)
        
        return categories

    def generate_smart_title(self, content: str) -> str:
        """ìŠ¤ë§ˆíŠ¸ ì œëª© ìƒì„±"""
        content_lower = content.lower()
        
        # í•µì‹¬ í‚¤ì›Œë“œ ê°ì§€
        keywords = []
        
        if 'asian' in content_lower and any(word in content_lower for word in ['stock', 'market']):
            keywords.append('ì•„ì‹œì•„ ì£¼ì‹ì‹œì¥')
        
        if any(word in content_lower for word in ['trump', 'trade', 'tariff']):
            keywords.append('ë¬´ì—­ì •ì±…')
        
        if any(word in content_lower for word in ['dollar', 'currency', 'exchange']):
            keywords.append('ë‹¬ëŸ¬')
        
        if 'deadline' in content_lower:
            keywords.append('ë§ˆê°ì¼')
        
        # ì œëª© êµ¬ì„±
        if keywords:
            if len(keywords) == 1:
                title = f"ğŸ“ˆ {keywords[0]} ë™í–¥"
            else:
                title = f"ğŸ“ˆ {keywords[0]}, {keywords[1]} ê´€ë ¨ ì†Œì‹"
        else:
            title = "ğŸ“° ê²½ì œ ë‰´ìŠ¤ ë¶„ì„"
        
        return title

    def extract_smart_keywords(self, content: str) -> str:
        """ìŠ¤ë§ˆíŠ¸ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # í•œêµ­ì–´ í‚¤ì›Œë“œ ìš°ì„  ì¶”ì¶œ
        korean_terms = []
        
        for en_term, ko_term in self.translation_dict.items():
            if en_term.lower() in content.lower():
                korean_terms.append(ko_term.replace(' ', ''))
        
        # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 5ê°œ ì„ íƒ
        unique_terms = list(dict.fromkeys(korean_terms))[:5]
        
        # í•´ì‹œíƒœê·¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        hashtags = [f"#{term}" for term in unique_terms]
        
        return ' '.join(hashtags) if hashtags else '#ê²½ì œë‰´ìŠ¤ #ì‹œì¥ë™í–¥'

    def read_txt_file(self, file_path: str) -> Dict[str, str]:
        """TXT íŒŒì¼ ì½ê¸°"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        title_match = re.search(r'ì œëª©: (.*?)\n={2,}', content)
        meta_match = re.search(r'ë©”íƒ€ ì •ë³´:\ndescription: (.*?)\n-{2,}', content, re.DOTALL)
        content_match = re.search(r'ë³¸ë¬¸:\n(.*?)$', content, re.DOTALL)
        
        return {
            'title': title_match.group(1) if title_match else "",
            'description': meta_match.group(1).strip() if meta_match else "",
            'content': content_match.group(1).strip() if content_match else ""
        }

    def convert_to_markdown(self, data: Dict[str, str]) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë³€í™˜"""
        full_content = f"{data['title']} {data['description']} {data['content']}"
        
        # ì œëª© ìƒì„±
        title = self.generate_smart_title(full_content)
        
        # ë‚´ìš© êµ¬ì¡°í™”
        structured = self.clean_and_structure(data['content'])
        
        # ë§ˆí¬ë‹¤ìš´ êµ¬ì„±
        markdown_parts = [title, ""]
        
        # ì‹œì¥ í˜„í™©
        if structured['market_status']:
            markdown_parts.append("â–¶ ì‹œì¥ í˜„í™©:")
            for item in structured['market_status'][:3]:
                translated = self.smart_translate(item)
                markdown_parts.append(f"â€¢ {translated}")
            markdown_parts.append("")
        
        # ê²½ì œ ì§€í‘œ
        if structured['economic_data']:
            markdown_parts.append("â–¶ ê²½ì œ ì§€í‘œ:")
            for item in structured['economic_data'][:2]:
                translated = self.smart_translate(item)
                markdown_parts.append(f"â€¢ {translated}")
            markdown_parts.append("")
        
        # ì •ì±…/ë¬´ì—­
        if structured['policy_trade']:
            markdown_parts.append("â–¶ ì •ì±… ë° ë¬´ì—­:")
            for item in structured['policy_trade'][:3]:
                translated = self.smart_translate(item)
                markdown_parts.append(f"â€¢ {translated}")
            markdown_parts.append("")
        
        # ì „ë§
        if structured['outlook']:
            markdown_parts.append("â–¶ í–¥í›„ ì „ë§:")
            for item in structured['outlook'][:2]:
                translated = self.smart_translate(item)
                markdown_parts.append(f"â€¢ {translated}")
            markdown_parts.append("")
        
        # í‚¤ì›Œë“œ
        keywords = self.extract_smart_keywords(full_content)
        markdown_parts.extend(["", keywords])
        
        return '\n'.join(markdown_parts)

    def process_file(self, file_path: str) -> None:
        """íŒŒì¼ ì²˜ë¦¬"""
        print(f"Processing {file_path} with Smart Converter...")
        
        data = self.read_txt_file(file_path)
        markdown_content = self.convert_to_markdown(data)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = f"{Path(file_path).stem}_smart_{timestamp}.md"
        output_path = self.output_dir / output_filename
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        
        print(f"Created {output_path}")

def main():
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python smart_converter.py <txt_file>")
        sys.exit(1)
    
    file_path = sys.argv[1]
    converter = SmartNewsConverter()
    
    if os.path.isfile(file_path):
        converter.process_file(file_path)
    else:
        print(f"Error: {file_path} is not a valid file")
        sys.exit(1)

if __name__ == '__main__':
    main() 