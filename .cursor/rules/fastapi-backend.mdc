---
globs: *.py
---

# FastAPI Backend Development Rules

## ðŸŽ¯ **BACKEND ARCHITECTURE**

### **Project Structure**
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â””â”€â”€ database.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â””â”€â”€ middleware.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ usage.py
â”‚   â”‚   â””â”€â”€ conversion.py
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ conversion.py
â”‚   â”‚   â””â”€â”€ response.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â”œâ”€â”€ conversion.py
â”‚   â”‚   â”‚   â””â”€â”€ users.py
â”‚   â”‚   â””â”€â”€ dependencies.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ news_extractor.py
â”‚   â”‚   â”œâ”€â”€ ai_converter.py
â”‚   â”‚   â”œâ”€â”€ user_service.py
â”‚   â”‚   â””â”€â”€ cache_service.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ tests/
â”œâ”€â”€ docker/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### **Core Dependencies**
```python
# requirements.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
pydantic-settings==2.1.0
sqlalchemy==2.0.23
asyncpg==0.29.0
redis==5.0.1
celery==5.3.4
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.6
httpx==0.25.2
openai==1.3.7
anthropic==0.8.1
selenium==4.15.2
beautifulsoup4==4.12.2
pytest==7.4.3
pytest-asyncio==0.21.1
```

## ðŸ”§ **DEVELOPMENT STANDARDS**

### **Code Quality Requirements**
```python
# Type hints are mandatory
from typing import Optional, List, Dict, Any, Union
from pydantic import BaseModel, Field, validator
from fastapi import FastAPI, HTTPException, Depends, status

# Example model with proper typing
class ConversionRequest(BaseModel):
    url: str = Field(..., description="News article URL")
    converter_type: Optional[str] = Field(None, description="AI converter type")
    user_id: int = Field(..., description="User ID")
    api_key: Optional[str] = Field(None, description="Custom API key")
    
    @validator('url')
    def validate_url(cls, v):
        if not v.startswith(('http://', 'https://')):
            raise ValueError('URL must start with http:// or https://')
        return v

class ConversionResponse(BaseModel):
    success: bool
    content: Optional[str] = None
    title: Optional[str] = None
    error: Optional[str] = None
    processing_time: float
    metadata: Dict[str, Any] = Field(default_factory=dict)
```

### **Error Handling Standards**
```python
# Custom exception classes
class NewsForgeException(Exception):
    """Base exception for NewsForge"""
    pass

class ExtractionException(NewsForgeException):
    """News extraction failed"""
    pass

class ConversionException(NewsForgeException):
    """AI conversion failed"""
    pass

class RateLimitException(NewsForgeException):
    """Rate limit exceeded"""
    pass

class UsageLimitException(NewsForgeException):
    """Usage limit exceeded"""
    pass

# Global exception handler
from fastapi import Request
from fastapi.responses import JSONResponse

@app.exception_handler(NewsForgeException)
async def newsforge_exception_handler(request: Request, exc: NewsForgeException):
    return JSONResponse(
        status_code=400,
        content={
            "success": False,
            "error": str(exc),
            "error_type": exc.__class__.__name__
        }
    )

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "error": exc.detail,
            "error_type": "HTTPException"
        }
    )
```

### **Logging Standards**
```python
import logging
import sys
from datetime import datetime
from typing import Dict, Any

# Configure structured logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('newsforge.log')
    ]
)

logger = logging.getLogger(__name__)

# Correlation ID middleware
import uuid
from fastapi import Request

@app.middleware("http")
async def add_correlation_id(request: Request, call_next):
    correlation_id = str(uuid.uuid4())
    request.state.correlation_id = correlation_id
    
    # Add to response headers
    response = await call_next(request)
    response.headers["X-Correlation-ID"] = correlation_id
    
    return response

# Structured logging helper
def log_conversion_attempt(
    url: str,
    user_id: int,
    correlation_id: str,
    status: str,
    processing_time: float = None,
    error: str = None
):
    log_data = {
        "event": "conversion_attempt",
        "url": url,
        "user_id": user_id,
        "correlation_id": correlation_id,
        "status": status,
        "timestamp": datetime.utcnow().isoformat(),
        "processing_time": processing_time,
        "error": error
    }
    
    if status == "success":
        logger.info(f"Conversion successful", extra=log_data)
    else:
        logger.error(f"Conversion failed", extra=log_data)
```

## ðŸš€ **SERVICE ARCHITECTURE**

### **News Extraction Service**
```python
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any
import httpx
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

class NewsExtractor(ABC):
    """Abstract base class for news extractors"""
    
    @abstractmethod
    async def extract(self, url: str) -> Dict[str, Any]:
        pass

class HTTPExtractor(NewsExtractor):
    """HTTP-based news extractor for static content"""
    
    def __init__(self):
        self.client = httpx.AsyncClient(timeout=30.0)
    
    async def extract(self, url: str) -> Dict[str, Any]:
        try:
            response = await self.client.get(url)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extract title
            title = soup.find('title')
            title_text = title.get_text().strip() if title else ""
            
            # Extract content
            content_selectors = [
                'article',
                '.article-content',
                '.post-content',
                '.entry-content'
            ]
            
            content = ""
            for selector in content_selectors:
                element = soup.select_one(selector)
                if element:
                    content = element.get_text().strip()
                    break
            
            return {
                "success": True,
                "title": title_text,
                "content": content,
                "url": url,
                "extractor_type": "http"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "url": url,
                "extractor_type": "http"
            }

class SeleniumExtractor(NewsExtractor):
    """Selenium-based extractor for dynamic content"""
    
    def __init__(self):
        self.options = Options()
        self.options.add_argument("--headless")
        self.options.add_argument("--no-sandbox")
        self.options.add_argument("--disable-dev-shm-usage")
        self.options.add_argument("--disable-gpu")
        self.options.add_argument("--disable-extensions")
    
    async def extract(self, url: str) -> Dict[str, Any]:
        driver = None
        try:
            driver = webdriver.Chrome(options=self.options)
            driver.set_page_load_timeout(30)
            driver.get(url)
            
            # Wait for content to load
            await asyncio.sleep(2)
            
            title = driver.title
            content = driver.find_element("tag name", "body").text
            
            return {
                "success": True,
                "title": title,
                "content": content,
                "url": url,
                "extractor_type": "selenium"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "url": url,
                "extractor_type": "selenium"
            }
        finally:
            if driver:
                driver.quit()

class ExtractorFactory:
    """Factory for creating appropriate extractors"""
    
    DYNAMIC_DOMAINS = ['yahoo', 'finance', 'bloomberg', 'cnbc', 'marketwatch']
    
    @classmethod
    def create_extractor(cls, url: str) -> NewsExtractor:
        if any(domain in url.lower() for domain in cls.DYNAMIC_DOMAINS):
            return SeleniumExtractor()
        return HTTPExtractor()
```

### **AI Conversion Service**
```python
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic
from typing import Optional, Dict, Any, List
import asyncio

class AIConverter:
    """AI-powered content converter"""
    
    def __init__(self):
        self.openai_client = AsyncOpenAI()
        self.anthropic_client = AsyncAnthropic()
    
    async def convert_to_social_content(
        self,
        article_data: Dict[str, Any],
        converter_type: Optional[str] = None,
        custom_api_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """Convert news article to social media content"""
        
        prompt = self._build_conversion_prompt(article_data)
        
        try:
            if converter_type == "openai" or not converter_type:
                content = await self._convert_with_openai(prompt, custom_api_key)
            elif converter_type == "anthropic":
                content = await self._convert_with_anthropic(prompt, custom_api_key)
            else:
                raise ValueError(f"Unknown converter type: {converter_type}")
            
            return {
                "success": True,
                "content": content,
                "converter_type": converter_type or "openai"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "converter_type": converter_type or "openai"
            }
    
    def _build_conversion_prompt(self, article_data: Dict[str, Any]) -> str:
        """Build conversion prompt for AI"""
        return f"""
        Convert this news article into engaging social media content.
        
        Original Title: {article_data.get('title', '')}
        Content: {article_data.get('content', '')[:2000]}...
        
        Requirements:
        1. Create 3 different versions (Twitter, LinkedIn, Instagram)
        2. Include relevant hashtags
        3. Maintain factual accuracy
        4. Make it engaging and shareable
        5. Keep platform-specific character limits in mind
        
        Format as JSON with keys: twitter, linkedin, instagram, hashtags
        """
    
    async def _convert_with_openai(
        self,
        prompt: str,
        custom_api_key: Optional[str] = None
    ) -> str:
        """Convert using OpenAI API"""
        
        client = AsyncOpenAI(api_key=custom_api_key) if custom_api_key else self.openai_client
        
        response = await client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a social media content expert."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
    
    async def _convert_with_anthropic(
        self,
        prompt: str,
        custom_api_key: Optional[str] = None
    ) -> str:
        """Convert using Anthropic API"""
        
        client = AsyncAnthropic(api_key=custom_api_key) if custom_api_key else self.anthropic_client
        
        response = await client.messages.create(
            model="claude-3-sonnet-20240229",
            max_tokens=1500,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        return response.content[0].text
```

### **User Service**
```python
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update
from datetime import datetime, timedelta
from typing import Optional, Dict, Any
import bcrypt

class UserService:
    """User management service"""
    
    def __init__(self, db: AsyncSession):
        self.db = db
    
    async def check_usage_limit(self, user_id: int) -> bool:
        """Check if user has exceeded usage limit"""
        
        user = await self.get_user_by_id(user_id)
        if not user:
            return False
        
        # Premium users have unlimited usage
        if user.plan_type == "premium":
            return True
        
        # Check daily usage for free users
        today = datetime.now().date()
        usage_count = await self.get_daily_usage_count(user_id, today)
        
        return usage_count < user.daily_limit
    
    async def increment_usage(self, user_id: int) -> None:
        """Increment user's daily usage count"""
        
        today = datetime.now().date()
        
        # Insert or update usage record
        await self.db.execute(
            """
            INSERT INTO user_usage (user_id, date, count)
            VALUES (:user_id, :date, 1)
            ON CONFLICT (user_id, date)
            DO UPDATE SET count = user_usage.count + 1
            """,
            {"user_id": user_id, "date": today}
        )
        
        await self.db.commit()
    
    async def get_user_stats(self, user_id: int) -> Dict[str, Any]:
        """Get user statistics"""
        
        today = datetime.now().date()
        this_month = datetime.now().replace(day=1).date()
        
        daily_usage = await self.get_daily_usage_count(user_id, today)
        monthly_usage = await self.get_monthly_usage_count(user_id, this_month)
        
        user = await self.get_user_by_id(user_id)
        
        return {
            "daily_usage": daily_usage,
            "daily_limit": user.daily_limit if user else 0,
            "monthly_usage": monthly_usage,
            "plan_type": user.plan_type if user else "free",
            "remaining_today": max(0, user.daily_limit - daily_usage) if user else 0
        }
```

## ðŸ“Š **PERFORMANCE OPTIMIZATION**

### **Caching Strategy**
```python
import redis.asyncio as redis
import json
from typing import Optional, Any
import hashlib

class CacheService:
    """Redis-based caching service"""
    
    def __init__(self, redis_url: str):
        self.redis = redis.from_url(redis_url)
    
    def _generate_cache_key(self, url: str, converter_type: str) -> str:
        """Generate cache key for conversion results"""
        key_data = f"{url}:{converter_type}"
        return f"conversion:{hashlib.md5(key_data.encode()).hexdigest()}"
    
    async def get_cached_conversion(
        self,
        url: str,
        converter_type: str
    ) -> Optional[Dict[str, Any]]:
        """Get cached conversion result"""
        
        cache_key = self._generate_cache_key(url, converter_type)
        cached_data = await self.redis.get(cache_key)
        
        if cached_data:
            return json.loads(cached_data)
        
        return None
    
    async def cache_conversion(
        self,
        url: str,
        converter_type: str,
        result: Dict[str, Any],
        ttl: int = 3600  # 1 hour
    ) -> None:
        """Cache conversion result"""
        
        cache_key = self._generate_cache_key(url, converter_type)
        cached_data = json.dumps(result)
        
        await self.redis.setex(cache_key, ttl, cached_data)
```

### **Rate Limiting**
```python
from fastapi import HTTPException, Request
from functools import wraps
import time
from typing import Dict, List
import asyncio

class RateLimiter:
    """Rate limiting service"""
    
    def __init__(self, redis_client):
        self.redis = redis_client
    
    async def check_rate_limit(
        self,
        user_id: int,
        limit: int,
        window: int = 3600  # 1 hour
    ) -> bool:
        """Check if user has exceeded rate limit"""
        
        key = f"rate_limit:{user_id}"
        current_time = int(time.time())
        window_start = current_time - window
        
        # Remove old entries
        await self.redis.zremrangebyscore(key, 0, window_start)
        
        # Count current requests
        current_count = await self.redis.zcard(key)
        
        if current_count >= limit:
            return False
        
        # Add current request
        await self.redis.zadd(key, {str(current_time): current_time})
        await self.redis.expire(key, window)
        
        return True

def rate_limit(limit: int, window: int = 3600):
    """Rate limiting decorator"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            request = kwargs.get('request') or args[0]
            user_id = getattr(request.state, 'user_id', None)
            
            if user_id:
                rate_limiter = RateLimiter(redis_client)
                if not await rate_limiter.check_rate_limit(user_id, limit, window):
                    raise HTTPException(
                        status_code=429,
                        detail="Rate limit exceeded"
                    )
            
            return await func(*args, **kwargs)
        return wrapper
    return decorator
```

## ðŸ” **SECURITY IMPLEMENTATION**

### **JWT Authentication**
```python
from jose import JWTError, jwt
from datetime import datetime, timedelta
from fastapi import HTTPException, status, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

class JWTHandler:
    """JWT token handler"""
    
    def __init__(self, secret_key: str, algorithm: str = "HS256"):
        self.secret_key = secret_key
        self.algorithm = algorithm
    
    def create_access_token(self, user_id: int, expires_delta: timedelta = None) -> str:
        """Create JWT access token"""
        
        to_encode = {"user_id": user_id}
        
        if expires_delta:
            expire = datetime.utcnow() + expires_delta
        else:
            expire = datetime.utcnow() + timedelta(hours=24)
            
        to_encode.update({"exp": expire})
        
        encoded_jwt = jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
        return encoded_jwt
    
    def verify_token(self, token: str) -> int:
        """Verify JWT token and return user ID"""
        
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            user_id: int = payload.get("user_id")
            
            if user_id is None:
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Invalid token"
                )
            
            return user_id
            
        except JWTError:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid token"
            )

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Get current user from JWT token"""
    
    jwt_handler = JWTHandler(settings.secret_key)
    user_id = jwt_handler.verify_token(credentials.credentials)
    
    return user_id
```

**Remember**: FastAPI is the high-performance engine. Keep it clean, async, and scalable. Every endpoint should handle errors gracefully and provide detailed logging for debugging.
description:
globs:
alwaysApply: false
---
